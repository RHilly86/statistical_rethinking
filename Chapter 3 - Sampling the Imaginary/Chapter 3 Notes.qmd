---
title: "Chapter 3 Notes"
format: html
---


```{python}
import pymc as pm
import polars as pl
from polars import col, lit
import numpy as np
import matplotlib.pyplot as plt
import arviz as az
from scipy import stats
from scipy.stats import binom
from toolz import frequencies, valmap
import seaborn as sns

plt.style.use("bmh")
```


```{python}
Pr_Positive_Vampire = 0.95
Pr_Positive_Mortal = 0.01
Pr_Vampire = 0.001
Pr_Positive = Pr_Positive_Vampire * Pr_Vampire + Pr_Positive_Mortal * (1 - Pr_Vampire)
Pr_Vampire_Positive = Pr_Positive_Vampire * Pr_Vampire / Pr_Positive

Pr_Vampire_Positive
```

## 3.1 Sampling from a grid-approximate posterior
```{python}
p_grid = np.linspace(0, 1, 1000)
prob_p = np.repeat(1, 1000)
prob_data = binom.pmf(6, 9, p_grid)
posterior = prob_data * prob_p
posterior = posterior / sum(posterior)
```

We can use our posterior distribution to sample values of $p$. Here, each value of $p$ will appear in proportion to the posterior plausibility of each value.
```{python}
samples = np.random.choice(p_grid, size=10000, replace=True, p=posterior)
```

```{python}
fig, ax = plt.subplots(figsize=(10, 5))
ax.scatter(list(range(samples.shape[0])), samples, alpha=0.25, color="black")
```

```{python}
fig, ax = plt.subplots(figsize=(10, 5))
ax.hist(samples, bins=30, color="black")
ax.grid(False)
```

```{python}
```

```{python}
```

## 3.2 Sampling to summarize

We can use our posterior distribution to answer questions like:

* How much posterior probability lies below a parameter value?
* How much posterior probability lies between two parameter values?
* Which parameter value marks the lower 5% of the posterior probability?
* Which range of parameter values contains 90% of the posterior probability?
* Which parameter value has the highest posterior probability?

### 3.2.1 Intervals of defined boundaries

We won't be able to do below since grid approximation isn't usually practical (especially with multiple parameters). However, we can use the samples we pulled above and do the same thing.
```{python}
np.sum(posterior[p_grid < 0.5])
```

Here, we do what we did above but using samples of $p$:

16.81% posterior probability lies below $p = 0.5$.
```{python}
np.sum(samples < 0.5) / 1e4
np.mean(samples < 0.5)
```

61.52% posterior probability lies between $p = 0.5 \text{ and } p = 0.75$
```{python}
np.sum((samples > 0.5) & (samples < 0.75)) / 1e4
np.mean((samples > 0.5) & (samples < 0.75))
```

### 3.2.2 Intervals of defined mass

We can also get how much posterior probability is between different hypothetical values of $p$.

For instance, we see that 80% of the posterior probability lies between 0 and 0.75:
```{python}
np.quantile(samples, 0.8)
```

While the middle 80% is between 0.445 and 0.812
```{python}
np.quantile(samples, [0.1, 0.9])
```

```{python}
fig, axes = plt.subplots(figsize=(12, 6), nrows=2, ncols=2)

for ax in axes.ravel():
    sns.kdeplot(samples, ax=ax)

x = np.linspace(0, 1, 10_000)
y = stats.gaussian_kde(samples)(x)

axes[0, 0].fill_between(x, y, where=x <= 0.5, alpha=0.5)
axes[0, 1].fill_between(x, y, where=(x >= 0.5) & (x <= 0.75), alpha=0.5)
axes[1, 0].fill_between(x, y, where=x <= 0.75, alpha=0.5)
axes[1, 1].fill_between(x, y, where=(x >= 0.475) & (x <= 0.775), alpha=0.5)
```

However, this method of finding the posterior probability between two values of $p$ is not as accurate when the distribution is asymmetric. 
```{python}
p_grid = np.linspace(0, 1, 1000)
prior = np.repeat(1, 1000)
likelihood = binom.pmf(6, 9, p_grid)
posterior = likelihood * prior
posterior = posterior / sum(posterior)
samples = np.random.choice(p_grid, size=10000, replace=True, p=posterior)
```

In those cases, we can use the **Highest Density Interval (HDI)**, which is the narrowest interval containing a certain amount of the posterior probability.
```{python}
az.hdi(samples, hdi_prob=0.5)
```

```{python}
p_grid[np.argmax(posterior)]
```

```{python}
np.mean(samples)
np.median(samples)
```

```{python}
np.sum(posterior * np.abs(0.5 - p_grid))
```

```{python}
loss = [
    np.sum(posterior * np.abs(p - p_grid))
    for p in p_grid
]
```

```{python}
p_grid[np.argmin(loss)]
```

## 3.3 Sampling to simulate prediction

### 3.3.1 Dummy data
```{python}
binom.pmf(np.arange(0, 3), 2, 0.7)
```

```{python}
binom.rvs(n=2, p=0.7, size=1)
```

```{python}
binom.rvs(n=2, p=0.7, size=10)
```

```{python}
dummy_w = binom.rvs(n=2, p=0.7, size=100_000)

valmap(lambda x: x / 100_000, frequencies(dummy_w))
```

```{python}
dummy_w = binom.rvs(n=9, p=0.7, size=100_000)
plt.hist(dummy_w, bins=50)
```

### 3.3.2 Model checking

#### 3.3.2.2 Is the model adequate?
```{python}
w = binom.rvs(n=9, p=0.6, size=100_000)
```

```{python}
w = binom(n=9, p=samples).rvs()
```

## 3.4 Summary

## 3.5 Practice

```{python}
```
