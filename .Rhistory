library(data.table)
library(rethinking)
library(tinyplot)
Pr_Positive_Vampire = 0.95
Pr_Positive_Mortal = 0.01
Pr_Vampire = 0.001
Pr_Positive = Pr_Positive_Vampire * Pr_Vampire + Pr_Positive_Mortal * (1 - Pr_Vampire)
Pr_Vampire_Positive = Pr_Positive_Vampire * Pr_Vampire / Pr_Positive
Pr_Vampire_Positive
p_grid = seq(0, 1, length.out = 1000)
prob_p = rep(1, 1000)
prob_data = dbinom(6, size = 9, prob = p_grid)
posterior = prob_data * prob_p
posterior = posterior / sum(posterior)
samples = sample(p_grid, prob = posterior, size = 1e4, replace = TRUE)
tinyplot(samples)
tinyplot(samples, type = "density")
tinyplot(samples, type = "density")
sum(posterior[p_grid < 0.5])
sum(samples < 0.5) / 1e4
sum(samples > 0.5 & samples < 0.75) / 1e4
sum(samples > 0.5 & samples < 0.75) / 1e4
quantile(samples, 0.8)
quantile(samples, c(0.1, 0.9))
p_grid = seq(0, 1, length.out = 1000)
prior = rep(1, 1000)
likelihood = dbinom(3, size = 3, prob = p_grid)
posterior = likelihood * prior
posterior = posterior / sum(posterior)
samples = sample(p_grid, size = 1e4, replace = TRUE, prob = posterior)
PI(samples, prob = 0.5)
HPDI(samples, prob = 0.5)
PI
concat
p_grid[which.max(posterior)]
chainmode(samples, adj = 0.01)
chainmod
chainmode
samples
samples |> attributes()
samples
chainmode
density(samples)
p_grid[which.min(loss)]
loss = sapply(p_grid, \(d) sum(posterior * abs(d - p_grid)))
p_grid[which.min(loss)]
dbinom(0:2, size = 2, prob = 0.7)
rbinom(1, size = 2, prob = 0.7)
rbinom(10, size = 2, prob = 0.7)
dummy_w = rbinom(1e5, size = 2, prob = 0.7)
table(dummy_w) / 1e5
dummy_w = rbinom(1e5, size = 9, prob = 0.7)
simplehist(dummy_w, xlab = "dummy water count")
w = rbinom(1e4, size = 9, prob = 0.6)
w = rbinom(1e4, size = 9, prob = samples)
p_grid = seq(0, 1, length.out = 1000)
prior = rep(1, 1000)
likelihood = dbinom(6, size = 9, prob = p_grid)
posterior = likelihood * prior
posterior = posterior / sum(posterior)
set.seed(100)
samples = sample(p_grid, prob = posterior, size = 1e4, replace = TRUE)
library(distributions3)
prob_dats
prob_data = dbinom(6, size = 9, prob = p_grid)
prob_data
?density
?pdf
pdf(Binomial(9, 6), p_grid)
warnings()
?Binomial
?dbinom
Binomial(9, p_grid)
pdf(Binomial(9, p_grid))
?Binomial
?pdf
Binomial(9, p_grid)
distributions3:::pdf.Binomial
pdf(Binomial(9, p_grid), 6)
prob_data = pdf(Binomial(9, prob_data), 6)
p_grid = seq(0, 1, length.out = 1000)
prob_p = rep(1, 1000)
prob_data = pdf(Binomial(9, prob_data), 6)
posterior = prob_data * prob_p
posterior = posterior / sum(posterior)
samples = sample(p_grid, prob = posterior, size = 1e4, replace = TRUE)
samples
tinyplot(samples)
args(Binomial)
# using distributions3
p_grid = seq(0, 1, length.out = 1000)
prob_p = rep(1, 1000)
# here, Binomial(size = 9, p = prob_data) creates
prob_data = pdf(Binomial(9, prob_p), 6)
posterior = prob_data * prob_p
posterior = posterior / sum(posterior)
samples = sample(p_grid, prob = posterior, size = 1e4, replace = TRUE)
# using distributions3
p_grid = seq(0, 1, length.out = 1000)
prob_p = rep(1, 1000)
# here, Binomial(size = 9, p = prob_data) creates
prob_data = pdf(Binomial(9, prob_p), 6)
posterior = prob_data * prob_p
posterior = posterior / sum(posterior)
samples = sample(p_grid, prob = posterior, size = 1e4, replace = TRUE)
# using distributions3
p_grid = seq(0, 1, length.out = 1000)
prob_p = rep(1, 1000)
# here, Binomial(size = 9, p = prob_data) creates
prob_data = pdf(Binomial(9, p_grid), 6)
posterior = prob_data * prob_p
posterior = posterior / sum(posterior)
samples = sample(p_grid, prob = posterior, size = 1e4, replace = TRUE)
tinyplot(samples)
prob_data
p_grid[1:10]
?pdf
p_grid
p_grid < 0.5
p_grid < 0.5 |> sum()
mean(p_grid < 0.5)
posterior
p_grid
posterior[p_grid < 0.5]
posterior[p_grid < 0.5] |> sum()
FALSE >= 0
library(data.table)
library(rethinking)
library(tinyplot)
library(distributions3)
Pr_Positive_Vampire = 0.95
Pr_Positive_Mortal = 0.01
Pr_Vampire = 0.001
Pr_Positive = Pr_Positive_Vampire * Pr_Vampire + Pr_Positive_Mortal * (1 - Pr_Vampire)
Pr_Vampire_Positive = Pr_Positive_Vampire * Pr_Vampire / Pr_Positive
Pr_Vampire_Positive
p_grid = seq(0, 1, length.out = 1000)
prob_p = rep(1, 1000)
prob_data = dbinom(6, size = 9, prob = p_grid)
posterior = prob_data * prob_p
posterior = posterior / sum(posterior)
# using distributions3
p_grid = seq(0, 1, length.out = 1000)
prob_p = rep(1, 1000)
# here, Binomial(size = 9, p = prob_data) creates 1000 Binomial distributions based on the grid approximation (p_grid) for pi.
# then we use pdf() to get the probability densities based on the number of successes
prob_data = pdf(Binomial(9, p_grid), 6)
posterior = prob_data * prob_p
posterior = posterior / sum(posterior)
samples = sample(p_grid, prob = posterior, size = 1e4, replace = TRUE)
plot(samples)
plot(density(samples))
sum(posterior[p_grid < 0.5])
sum(samples < 0.5) / 1e4
# using distributions3
p_grid = seq(0, 1, length.out = 1000)
prob_p = rep(1, 1000)
# here, Binomial(size = 9, p = prob_data) creates 1000 Binomial distributions based on the grid approximation (p_grid) for pi.
# then we use pdf() to get the probability densities based on the number of successes
prob_data = pdf(Binomial(9, p_grid), 6)
posterior = prob_data * prob_p
posterior = posterior / sum(posterior)
samples = sample(p_grid, prob = posterior, size = 1e4, replace = TRUE)
dens(samples)
sum(posterior[p_grid < 0.5])
mean(samples < 0.5)
sum(samples < 0.5) / 1e4
mean(samples > 0.5 & samples < 0.75)
?quantile
quantile(samples, 0.8)
quantile(samples, c(0.1, 0.9))
dens
