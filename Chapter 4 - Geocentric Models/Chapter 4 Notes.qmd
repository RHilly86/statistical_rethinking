---
title: "Chapter 4 Notes"
format: html
---

```{r}
library(MASS)
library(collapse)
library(rethinking)
library(splines)
library(distributions3)

set_collapse(mask = "manip")
```

## 4.1 Why normal distributions are normal

### 4.1.1 Normal by addition
```{r}
pos = replicate(1000, sum(random(Uniform(a = -1, b = 1), 16)))
```

### 4.1.2 Normal by multiplication
```{r}
prod(1 + random(Uniform(a = 0, b = 0.1), 12))
```

```{r}
growth = replicate(10000, prod(1 + random(Uniform(a = 0, b = 0.1), 12)))
dens(growth, norm.comp = TRUE)
```

```{r}
big = replicate(10000, prod(1 + random(Uniform(a = 0, b = 0.5), 12)))
small = replicate(10000, prod(1 + random(Uniform(a = 0, b = 0.01), 12)))
```

### 4.1.3 Normal by log-multiplication
```{r}
log_big = replicate(10000, log(prod(1 + random(Uniform(a = 0, b = 0.5), 12))))
```

### 4.1.4 Using Gaussian distributions

## 4.2 A language for describing models

### 4.2.1 Re-describing the globe tossing model
```{r}
w = 6; n = 9;
p_grid = seq(0, 1, length.out = 100)
posterior = pdf(Binomial(size = n, p = p_grid), w) * pdf(Uniform(a = 0, b = 1), p_grid)
posterior = posterior / sum(posterior)
```

## 4.3 Gaussian model of height

### 4.3.1 The data
```{r}
data(Howell1)
d = Howell1
```

```{r}
str(d)
```

```{r}
precis(d)
```

```{r}
d$height
```

```{r}
d2 = subset(d, age >= 18)
```

### 4.3.2 The model

```{r}
curve(pdf(Normal(mu = 178, sigma = 20), x), from = 100, to = 250)
```

```{r}
curve(pdf(Uniform(a = 0, b = 50), x), from = -10, to = 60)
```

```{r}
sample_mu = random(Normal(mu = 178, sigma = 20), 10000)
sample_sigma = random(Uniform(a = 0, b = 50), 10000)
prior_h = random(Normal(mu = sample_mu, sigma = sample_sigma))
dens(prior_h)
```

```{r}
sample_mu = random(Normal(mu = 178, sigma = 100), 10000)
prior_h = random(Normal(mu = sample_mu, sigma = sample_sigma))
dens(prior_h)
```

### 4.3.3 Grid approximation of the posterior distribution
```{r}
mu_list = seq(150, 160, length.out = 100)
sigma_list = seq(7, 9, length.out = 100)
post = expand.grid(mu = mu_list, sigma = sigma_list)

post$LL = sapply(1:nrow(post), \(i) sum(
    log_pdf(Normal(mu = post$mu[i], sigma = post$sigma[i]), d2$height)
))
post$prod = post$LL + log_pdf(Normal(mu = 178, sigma = 20), post$mu) + log_pdf(Uniform(a = 0, b = 50), post$sigma)
post$prob = exp(post$prod - max(post$prod))
```

```{r}
contour_xyz(post$mu, post$sigma, post$prob)
```

```{r}
image_xyz(post$mu, post$sigma, post$prob)
```

### 4.3.4 Sampling from the posterior
```{r}
sample_rows = sample(1:nrow(post), size = 10000, prob = post$prob, replace = TRUE)
sample_mu = post$mu[sample_rows]
sample_sigma = post$sigma[sample_rows]
```

```{r}
plot(sample_mu, sample_sigma, cex = 0.5, pch = 16, col = col.alpha(rangi2, 0.1))
```

```{r}
dens(sample_mu)
dens(sample_sigma)
```

```{r}
PI(sample_mu)
PI(sample_sigma)
```

```{r}
d3 = sample(d2$height, size = 20)
```

```{r}
mu_list = seq(150, 170, length.out = 200)
sigma_list = seq(4, 20, length.out = 200)
post2 = expand.grid(mu = mu_list, sigma = sigma_list)

post2$LL = sapply(1:nrow(post2), \(i) sum(
    log_pdf(Normal(mu = post2$mu[i], sigma = post2$sigma[i]), d3)
))
post2$prod = post2$LL + log_pdf(Normal(mu = 178, sigma = 20), post2$mu) + log_pdf(Uniform(a = 0, b = 50), post2$sigma)

sample2_rows = sample(1:nrow(post2), size = 1e4, prob = post2$prob, replace = TRUE)
sample2_mu = post2$mu[sample2_rows]
sample2_sigma = post2$sigma[sample2_rows]

plot(sample2_mu, sample2_sigma, cex = 0.5,
     col = col.alpha(rangi2, 0.1),
     xlab = "mu", ylab = "sigma", pch = 16)
```

```{r}
dens(sample2_sigma, norm.comp = TRUE)
```

### 4.3.5 Finding the posterior distribution with `quap`

```{r}
flist = alist(
    height ~ dnorm(mu, sigma),
    mu ~ dnorm(178, 20),
    sigma ~ dunif(0, 50)
)
```

```{r}
m4_1 = quap(flist, data = d2)
```

```{r}
precis(m4_1)
```

```{r}
m4_2 = quap(
    alist(
        height ~ dnorm(mu, sigma),
        mu ~ dnorm(178, 0.1),
        sigma ~ dunif(0, 50)
    ),
    data = d2
)
precis(m4_2)
```

### 4.3.6 Sampling from a `quap`
```{r}
vcov(m4_1)
```

```{r}
diag(vcov(m4_1))
cov2cor(vcov(m4_1))
```

```{r}
post = extract.samples(m4_1, n = 1e4)
```

```{r}
head(post)
precis(post)
```

```{r}
post = mvrnorm(n = 1e4, mu = coef(m4_1), Sigma = vcov(m4_1))
```

## 4.4 Linear prediction

```{r}
plot(d2$height ~ d2$weight)
```

### 4.4.1 The linear model strategy

#### 4.4.1.1 Probability of the data

#### 4.4.1.2 Linear model

#### 4.4.1.3 Priors
```{r}
set.seed(2971)

N = 100
a = random(Normal(mu = 178, sigma = 20), N)
b = random(Normal(mu = 0, sigma = 10), N)
```

```{r}
plot(NULL, xlim = range(d2$weight), ylim = c(-100, 400),
           xlab = "weight", ylab = "height")
abline(h = 0, lty = 2)
abline(h = 272, lty = 1, lwd = 0.5)
mtext("b ~ dnorm(0, 10)")
xbar = mean(d2$weight)

for (i in 1:N) {
    curve(a[i] + b[i] * (x - xbar),
    from = min(d2$weight), to = max(d2$weight), add = TRUE,
    col = col.alpha("black", 0.2))
}
```

```{r}
b = random(LogNormal(log_mu = 0, log_sigma = 1), 1e4)
dens(b, xlim = c(0, 5), adj = 0.1)
```

```{r}
set.seed(2971)

N = 100
a = random(Normal(mu = 178, sigma = 20), N)
b = random(LogNormal(log_mu = 0, log_sigma = 1), N)
```

### 4.4.2 Finding the posterior distribution
```{r}
xbar = mean(d2$weight)

m4_3 = quap(
    alist(
        height ~ dnorm(mu, sigma),
        mu <- a + b * (weight - xbar),
        a ~ dnorm(178, 20),
        b ~ dlnorm(0, 1),
        sigma ~ dunif(0, 50)
    ),
    data = d2
)
```

```{r}
m4_3b = quap(
    alist(
        height ~ dnorm(mu, sigma),
        mu <- a + exp(log_b) * (weight - xbar),
        a ~ dnorm(178, 20),
        log_b ~ dnorm(0, 1),
        sigma ~ dunif(0, 50)
    ),
    data = d2
)
```

### 4.4.3 Interpreting the posterior distribution

#### 4.4.3.1 Tables of marginal distributions
```{r}
precis(m4_3)
```

```{r}
round(vcov(m4_3), 3)
```

#### 4.4.3.2 Plotting posterior inference against the data
```{r}
plot(height ~ weight, data = d2, col = rangi2)
post = extract.samples(m4_3)
a_map = mean(post$a)
b_map = mean(post$b)
curve(a_map + b_map * (x - xbar), add = TRUE)
```

#### 4.4.3.3 Adding uncertainty around the mean
```{r}
post = extract.samples(m4_3)
post[1:5, ]
```

```{r}
N = 10
dN = d2[1:N, ]
mN = quap(
    alist(
        height ~ dnorm(mu, sigma),
        mu <- a + b * (weight - mean(weight)),
        a ~ dnorm(178, 20),
        b ~ dlnorm(0, 1),
        sigma ~ dunif(0, 50)
    ),
    data = dN
)
```

```{r}
post = extract.samples(mN, n = 20)

plot(dN$weight, dN$height,
     xlim = range(d2$weight), ylim = range(d2$height),
     col = rangi2, xlab = "weight", ylab = "height")
mtext(concat("N = ", N))

for (i in 1:20) {
    curve(post$a[i] + post$b[i] * (x - mean(dN$weight)),
          col = col.alpha("black", 0.3), add = TRUE)
}
```

#### 4.4.3.4 Plotting regression intervals and contours
```{r}
post = extract.samples(m4_3)
mu_at_50 = post$a + post$b * (50 - xbar)
```

```{r}
dens(mu_at_50, col = rangi2, lwd = 2, xlab = "mu|weight=50")
```

```{r}
PI(mu_at_50, prob = 0.89)
```

```{r}
mu = link(m4_3)
str(mu)
```

```{r}
weight_seq = seq(25, 70, by = 1)
mu = link(m4_3, data = data.frame(weight = weight_seq))
str(mu)
```

```{r}
plot(height ~ weight, d2, type = "n")

for (i in 1:100) {
    points(weight_seq, mu[i, ], pch = 16, col = col.alpha(rangi2, 0.1))
}
```

```{r}
mu_mean = apply(mu, 2, mean)
mu_PI = apply(mu, 2, PI, prob = 0.89)
```

```{r}
plot(height ~ weight, data = d2, col = col.alpha(rangi2, 0.5))
lines(weight_seq, mu_mean)
shade(mu_PI, weight_seq)
```

#### 4.4.3.5 Prediction intervals
```{r}
sim_height = sim(m4_3, data = list(weight = weight_seq))
str(sim_height)
```

```{r}
height_PI = apply(sim_height, 2, PI, prob = 0.89)
```

```{r}
plot(height ~ weight, d2, col = col.alpha(rangi2, 0.5))
lines(weight_seq, mu_mean)
shade(mu_PI, weight_seq)
shade(height_PI, weight_seq)
```

```{r}
sim_height = sim(m4_3, data = list(weight = weight_seq), n = 1e4)
height_PI = apply(sim_height, 2, PI, prob = 0.89)
```

## 4.5 Curves from lines

### 4.5.1 Polynomial regression
```{r}
d$weight_s = (d$weight - mean(d$weight)) / sd(d$weight)
d$weight_s2 = d$weight_s ^ 2
m4_5 = quap(
    alist(
        height ~ dnorm(mu, sigma),
        mu <- a + b1 * weight_s + b2 * weight_s2,
        a ~ dnorm(178, 20),
        b1 ~ dlnorm(0, 1),
        b2 ~ dnorm(0, 1),
        sigma ~ dunif(0, 50)
    ),
    data = d
)
```

```{r}
precis(m4_5)
```

```{r}
weight_seq = seq(-2.2, 2, length.out = 30)
pred_dat = list(weight_s = weight_seq, weight_s2 = weight_seq ^ 2)

mu = link(m4_5, data = pred_dat)
mu_mean = apply(mu, 2, mean)
mu_PI = apply(mu, 2, PI, prob = 0.89)

sim_height = sim(m4_5, data = pred_dat)
height_PI = apply(sim_height, 2, PI, prob = 0.89)
```

```{r}
plot(height ~ weight_s, d, col = col.alpha(rangi2, 0.5))
lines(weight_seq, mu_mean)
shade(mu_PI, weight_seq)
shade(height_PI, weight_seq)
```

```{r}
d$weight_s3 = d$weight_s ^ 3
m4_6 = quap(
    alist(
        height ~ dnorm(mu, sigma),
        mu <- a + b1 * weight_s + b2 * weight_s2 + b3 * weight_s3,
        a ~ dnorm(178, 20),
        b1 ~ dlnorm(0, 1),
        b2 ~ dnorm(0, 10),
        b3 ~ dnorm(0, 10),
        sigma ~ dunif(0, 50)
    ),
    data = d
)
```

```{r}
plot(height ~ weight_s, d, col = col.alpha(rangi2, 0.5), xaxt = "n")
```

```{r}
at = c(-2, -1, 0, 1, 2)
labels = at * sd(d$weight) + mean(d$weight)
axis(side = 1, at = at, labels = round(labels, 1))
```

### 4.5.2 Splines
```{r}
data(cherry_blossoms)
d = cherry_blossoms
precis(d)
```

```{r}
d2 = d[complete.cases(d$doy), ]
num_knots = 15
knot_list = quantile(d2$year, probs = seq(0, 1, length.out = num_knots))
```

```{r}
B = bs(d2$year,
       knots = knot_list[-c(1, num_knots)],
       degree = 3, intercept = TRUE)
```

```{r}
plot(NULL, xlim = range(d2$year), ylim = c(0, 1),
     xlab = "year", ylab = "basis")
for (i in 1:ncol(B)) {
    lines(d2$year, B[, i])
}
```

```{r}
m4_7 = quap(
    alist(
        D ~ dnorm(mu, sigma),
        mu <- a + B %*% w,
        a ~ dnorm(100, 10),
        w ~ dnorm(0, 10),
        sigma ~ dexp(1)
    ),
    data = list(D = d2$doy, B = B),
    start = list(w = rep(0, ncol(B)))
)
```

```{r}
post = extract.samples(m4_7)
w = apply(post$w, 2, mean)
plot(NULL, xlim = range(d2$year), ylim = c(-6, 6),
     xlab = "year", ylab = "basis * weight")
for (i in 1:ncol(B)) {
    lines(d2$year, w[i] * B[, i])
}
```

```{r}
m4_7alt = quap(
    alist(
        D ~ dnorm(mu, sigma),
        mu <- a + sapply(1:827, \(i) sum(B[i, ] * w)),
        a ~ dnorm(100, 1),
        w ~ dnorm(0, 10),
        sigma ~ dexp(1)
    ),
    data = list(D = d2$doy, B = B),
    start = list(w = rep(0, ncol(B)))
)
```

### 4.5.3 Smooth functions for a rough world

## 4.6 Summary

## 4.7 Practice

### 4E1

### 4E2

### 4E4

### 4E5

### 4M1

### 4M2

### 4M3

### 4M4

### 4M5

### 4M6

### 4M7

### 4M8

### 4H1

### 4H2

### 4H3

### 4H4

### 4H5

### 4H6

### 4H7