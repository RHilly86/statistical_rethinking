---
title: "Chapter 4 Notes"
format: html
---

```{julia}
using DataFrames
using DataFramesMeta
using Distributions
using CairoMakie
using StatsBase
using StatisticalRethinking
using Turing
using RDatasets
using CSV
using BSplines
```

## 4.1 Why normal distributions are normal

### 4.1.1 Normal by additio

```{julia}
pos = vec(sum(rand(Uniform(-1, 1), (1000, 16)), dims=2))
```

### 4.1.2 Normal by multiplication

```{julia}
prod(1 .+ rand(Uniform(0, 0.1), 12))
```

```{julia}
growth = vec(prod(1 .+ rand(Uniform(0, 0.1), (10_000, 12)), dims=2))
density(growth)
```

```{julia}
big = vec(prod(1 .+ rand(Uniform(0, 0.5), (10_000, 12)), dims=2))
small = vec(prod(1 .+ rand(Uniform(0, 0.01), (10_000, 12)), dims=2))
```


### 4.1.3 Normal by log-multiplication

```{julia}
log_big = vec(log.(prod(1 .+ rand(Uniform(0, 0.5), (10_000, 12)), dims=2)))
```

### 4.1.4 Using Gaussian distributions

## 4.2 A language for describing models

### 4.2.1 Re-describing the globe tossing model

```{julia}
w = 6 
n = 9
p_grid = range(start=0, stop=1, length=100)
posterior = pdf.(Binomial.(n, p_grid), w) .* pdf.(Uniform(0, 1), p_grid)
posterior = posterior / sum(posterior)
```

## 4.3 Gaussian model of height

### 4.3.1 The data

```{julia}
d = CSV.read("Chapter 4 - Geocentric Models/Howell1.csv", DataFrame)
```

```{julia}
d[:, :height]
```

```{julia}
d2 = d[d.age .>= 18, :]
```

### 4.3.2 The model

```{julia}
x = 100:250
y = pdf.(Normal(178, 20), x)

lines(x, y)
```

```{julia}
x = -10:60
y = pdf.(Uniform(0, 50), x)

lines(x, y)
```

```{julia}
sample_mu = rand(Normal(178, 20), 10_000)
sample_sigma = rand(Uniform(0, 50), 10_000)
prior_h = rand.(Normal.(sample_mu, sample_sigma))

density(prior_h)
```

```{julia}
sample_mu = rand(Normal(178, 100), 10_000)
prior_h = rand.(Normal.(sample_mu, sample_sigma))

density(prior_h)
```

### 4.3.3 Grid approximation of the posterior distribution

```{julia}
mu_list = range(start=150, stop=160, length=100)
sigma_list = range(start=7, stop=9, length=100)
post = DataFrame(Iterators.product(mu_list, sigma_list), [:mu, :sigma])

LL = map(i -> sum(logpdf.(Normal(post.mu[i], post.sigma[i]), d2.height)), 1:nrow(post))
LL_prod = LL + logpdf.(Normal(178, 20), post.mu) + logpdf.(Uniform(0, 50), post.sigma)
prob = exp.(LL_prod .- maximum(LL_prod))

@transform!(post, :LL=LL, :prod=LL_prod, :prob=prob)
```

```{julia}
contour(post.mu, post.sigma, post.prob)
```


### 4.3.4 Sampling from the posterior

```{julia}
sample_rows = sample(1:nrow(post), Weights(post.prob), 10_000, replace=true)
sample_mu = post.mu[sample_rows]
sample_sigma = post.sigma[sample_rows]
```

```{julia}
scatter(sample_mu, sample_sigma)
```

```{julia}
density(sample_mu)
```

```{julia}
density(sample_sigma)
```

```{julia}
PI(sample_mu)
```

```{julia}
PI(sample_sigma)
```

```{julia}
d3 = sample(d2.height, 20)
```

```{julia}
mu_list = range(start=150, stop=170, length=200)
sigma_list = range(start=4, stop=20, length=200)
post2 = DataFrame(Iterators.product(mu_list, sigma_list), [:mu, :sigma])

LL = map(i -> sum(logpdf.(Normal(post2.mu[i], post2.sigma[i]), d3)), 1:nrow(post2))
LL_prod = LL + logpdf.(Normal(178, 20), post2.mu) + logpdf.(Uniform(0, 50), post2.sigma)
prob = exp.(LL_prod .- maximum(LL_prod))

@transform!(post2, :LL=LL, :prod=LL_prod, :prob=prob)

sample2_rows = sample(1:nrow(post2), Weights(post2.prob), 10_000, replace=true)
sample2_mu = post2.mu[sample2_rows]
sample2_sigma = post2.sigma[sample2_rows]
``` 

```{julia}
scatter(sample2_mu, sample2_sigma)
```

```{julia}
density(sample2_sigma)
```

```{r}
dens(sample2_sigma, norm.comp = TRUE)
```

### 4.3.5 Finding the posterior distribution with `quap`

```{julia}
@model function m4_1(height)
    μ ~ Normal(178, 20)
    σ ~ Uniform(0, 50)

    return height ~ Normal(μ, σ)
end
```

```{julia}
m4_1_samples = sample(m4_1(d2.height), NUTS(), MCMCThreads(), 1000, 4)
```

```{julia}
m4_1_samples
```

```{julia}
@model function m4_2(height)
    μ ~ Normal(178, 0.1)
    σ ~ Uniform(0, 50)

    return height ~ Normal(μ, σ)
end
```

```{julia}
m4_2_samples = sample(m4_2(d2.height), NUTS(), MCMCThreads(), 1000, 4)
```


### 4.3.6 Sampling from a `quap`
```{r}
vcov(m4_1)
```

```{r}
diag(vcov(m4_1))
cov2cor(vcov(m4_1))
```

```{julia}
post = DataFrame(m4_2_samples)
```

```{r}
head(post)
precis(post)
```

```{r}
post = mvrnorm(n = 1e4, mu = coef(m4_1), Sigma = vcov(m4_1))
```

## 4.4 Linear prediction

```{julia}
scatter(d2.weight, d2.height)
```

### 4.4.1 The linear model strategy

#### 4.4.1.1 Probability of the data

#### 4.4.1.2 Linear model

#### 4.4.1.3 Priors

```{julia}
N = 100
a = rand(Normal(178, 20), N)
b = rand(Normal(0, 10), N)
```

```{julia}
xbar = mean(d2.weight)
x = range(start=minimum(d2.weight), stop=maximum(d2.weight), length=N)

fig = Figure()
ax = Axis(fig[1, 1])

for i in 1:N
    mu = a[i] .+ b[i] .* (x .- xbar)
    lines!(ax, x, mu, color=:black, alpha=0.4)
end

fig
```

```{julia}
b = rand(LogNormal(0, 1), 10_000)
density(b)
```

```{julia}
N = 100
a = rand(Normal(178, 20), N)
b = rand(LogNormal(0, 1), N)
```





### 4.4.2 Finding the posterior distribution
```{julia}
xbar = mean(d2.weight)

@model function m4_3(height, weight)
    α ~ Normal(178, 20)
    β ~ LogNormal(0, 1)
    σ ~ Uniform(0, 50)

    μ = α .+ β .* (weight .- xbar)
    
    for i in eachindex(height)
        height[i] ~ Normal(μ[i], σ)
    end
end
```

```{julia}
m4_3_samples = sample(m4_3(d2.height, d2.weight), NUTS(), MCMCThreads(), 1000, 4)
```

```{julia}
@model function m4_3b(height, weight)
    α ~ Normal(178, 20)
    log_β ~ Normal(0, 1)
    σ ~ Uniform(0, 50)

    μ = α .+ exp.(log_β) .* (weight .- xbar)

    for i in eachindex(height)
        height[i] ~ Normal(μ[i], σ)
    end
end
```

```{julia}
m4_3b_samples = sample(m4_3b(d2.height, d2.weight), NUTS(), MCMCThreads(), 1000, 4)
```

### 4.4.3 Interpreting the posterior distribution

#### 4.4.3.1 Tables of marginal distributions
```{r}
precis(m4_3)
```

```{r}
round(vcov(m4_3), 3)
```

#### 4.4.3.2 Plotting posterior inference against the data

```{julia}
post = DataFrame(m4_3_samples)
a_map = mean(post.α)
b_map = mean(post.β)
mu = a_map .+ b_map .* (x .- xbar)

fig = Figure()
ax = Axis(fig[1, 1])

scatter!(ax, d2.weight, d2.height)
lines!(ax, x, mu, color=:black)
fig
```

#### 4.4.3.3 Adding uncertainty around the mean

```{julia}
post = DataFrame(m4_3_samples)
post[1:5, :]
```

```{julia}
N = 10
dN = d2[1:N, :]
x = range(start=minimum(d2.weight), stop=maximum(d2.weight), length=N)

@model function mN(height, weight)
    α ~ Normal(178, 20)
    β ~ LogNormal(0, 1)
    σ ~ Uniform(0, 50)

    μ = α .+ β .* (weight .- mean(weight))

    for i in eachindex(height)
        height[i] ~ Normal(μ[i], σ)
    end
    return μ
end
```

```{julia}
mN_samples = sample(mN(dN.height, dN.weight), NUTS(), MCMCThreads(), 1000, 4)
```

```{julia}
post = sample(DataFrame(mN_samples), 20, replace=false)

fig = Figure()
ax = Axis(fig[1, 1])

scatter!(dN.weight, dN.height)
for i in 1:20
    mu = post.α[i] .+ post.β[i] .* (x .- mean(dN.weight))
    lines!(ax, x, mu, color=:black, alpha=0.5)
end

fig
```


#### 4.4.3.4 Plotting regression intervals and contours

```{julia}
post = DataFrame(m4_3_samples)
mu_at_50 = post.α .+ post.β .* (50 - xbar)
```

```{julia}
density(mu_at_50)
```

```{julia}
PI(mu_at_50; perc_prob=0.89)
```

```{julia}
mu = vec(mean.(generated_quantities(mN(dN.height, dN.weight), mN_samples)))
```

```{julia}
weight_seq = 25:70
mu_link = StatisticalRethinking.link(post, [:α, :β], weight_seq, xbar)
mu = hcat(mu_link...)

mu
```

```{julia}
fig = Figure()
ax1 = Axis(fig[1, 1])
ax2 = Axis(fig[1, 2])

for i in 1:100
    scatter!(ax1, weight_seq, mu[i, :], color=:blue, alpha=0.3)
end

mu_mean = vec(mean(mu, dims=1))
mu_PI = mapslices(x -> PI(x; perc_prob=0.89), mu, dims=1)

scatter!(ax2, d2.weight, d2.height)
lines!(ax2, weight_seq, mu_mean)
band!(ax2, weight_seq, mu_PI[1, :], mu_PI[2, :], color=:gray, alpha=0.1)

fig
```

#### 4.4.3.5 Prediction intervals

```{julia}
sim_height = simulate(post, [:α, :β, :σ], weight_seq .- xbar)
height_PI = mapslices(x -> PI(x; perc_prob=0.89), sim_height, dims=1)
mu_HPDI = mapslices(x -> hpdi(x; alpha=0.89), mu, dims=1)
```

```{julia}
fig = Figure()
ax = Axis(fig[1, 1])

scatter!(ax, d2.weight, d2.height)
lines!(ax, weight_seq, mu_mean)
band!(ax, weight_seq, mu_HPDI[1, :], mu_HPDI[2, :],  color=:gray)
band!(ax, weight_seq, height_PI[1, :], height_PI[2, :], color=:gray, alpha=0.2)

fig
```

## 4.5 Curves from lines

### 4.5.1 Polynomial regression

```{julia}
d = CSV.read("Chapter 4 - Geocentric Models/Howell1.csv", DataFrame)
```
```{julia}
d = @chain d begin
        @transform(:weight_s = (:weight .- mean(:weight)) / std(:weight))
        @rtransform(:weight_s2 = :weight_s ^ 2)
end
```

```{julia}
@model function m4_5(height, weight_s, weight_s2)
    α ~ Normal(178, 20)
    β₁ ~ LogNormal(0, 1)
    β₂ ~ Normal(0, 1)
    σ ~ Uniform(0, 50)

    μ = α .+ β₁ .* weight_s .+ β₂ .* weight_s2

    for i in eachindex(weight_s)
        height[i] ~ Normal(μ[i], σ)
    end
end
```

```{julia}
m4_5_samples = sample(m4_5(d.height, d.weight_s, d.weight_s2), NUTS(), MCMCThreads(), 1000, 4)
```

```{r}
precis(m4_5)
```

```{julia}
weight_seq = range(start=-2.2, stop=2, length=30)
weight_s2 = weight_seq .^2
post = DataFrame(m4_5_samples)

mu_link = StatisticalRethinking.link(post, (r, x) -> r.α + r.β₁ * x + r.β₂ * x ^ 2, weight_seq)
mu = hcat(mu_link...)
mu_mean = vec(mean(mu, dims=1))

sim_height = simulate(post, (r, x) -> Normal(r.α + r.β₁ * x + r.β₂ * x ^ 2, r.σ), weight_seq)
sim_height = transpose(hcat(sim_height...))
height_PI = mapslices(x -> PI(x; perc_prob=0.89), sim_height, dims=1)
```

```{julia}
fig = Figure()
ax = Axis(fig[1, 1])

scatter!(ax, d.weight_s, d.height)
lines!(ax, weight_seq, mu_mean)
band!(ax, weight_seq, height_PI[1, :], height_PI[2, :], alpha=0.3)

fig
```

```{julia}
@rtransform!(d, :weight_s3 = :weight_s ^ 3)

@model function m4_6(height, weight_s, weight_s2, weight_s3)
    α ~ Normal(178, 20)
    β₁ ~ LogNormal(0, 1)
    β₂ ~ Normal(0, 10)
    β₃ ~ Normal(0, 10)
    σ ~ Uniform(0, 50)

    μ = α .+ β₁ .* weight_s .+ β₂ .* weight_s2 .+ β₃ .* weight_s3
    for i in eachindex(weight_s)
        height[i] ~ Normal(μ[i], σ)
    end
end
```

```{julia}
m4_6_samples = sample(m4_6(d.height, d.weight_s, d.weight_s2, d.weight_s3), NUTS(), MCMCThreads(), 1000, 4)
```

### 4.5.2 Splines
```{julia}
d = CSV.read("Chapter 4 - Geocentric Models/cherry_blossoms.csv", DataFrame; missingstring="NA")
```

```{julia}
d2 = dropmissing(d, :doy)
num_knots = 15
knots_list = quantile(d2.year, range(start=0, stop=1, length=num_knots))
```

```{julia}
basis = BSplineBasis(3, knots_list)

xs = Matrix{Float64}(undef, 100, length(basis))
ys = similar(xs)

for (j, bspline) in enumerate(basis)
    xmin, xmax = BSplines.support(bspline)
    for (i, x) in enumerate(range(start=xmin, stop=xmax, length=100))
        xs[i, j] = x
        ys[i, j] = bspline(x)
    end
end
```

```{julia}
```

```{julia}
fig = Figure()
ax = Axis(fig[1, 1])
num_cols = size(xs)[2]

for j in 1:num_cols
    lines!(ax, xs[:, j], ys[:, j])
end

fig
```

```{julia}
@model function m4_7(year, doy)
    γ ~ MvNormal(zeros(length(basis)), 1)
    α ~ Normal(100, 10)
    s = Spline(basis, γ)
    σ ~ Exponential(1)

    μ = α .+ s.(year)
    for i in eachindex(doy)
        Normal(μ[i], σ)
    end
end

m4_7_samples = sample(m4_7(d2.year, d2.doy), NUTS(0.65; init_ϵ = 9.765625e-5), MCMCThreads(), 1000, 4)
```

```{julia}
post = DataFrame(m4_7_samples)
```

```{r}
post = extract.samples(m4_7)
w = apply(post$w, 2, mean)
plot(NULL, xlim = range(d2$year), ylim = c(-6, 6),
     xlab = "year", ylab = "basis * weight")
for (i in 1:ncol(B)) {
    lines(d2$year, w[i] * B[, i])
}
```

```{r}
m4_7alt = quap(
    alist(
        D ~ dnorm(mu, sigma),
        mu <- a + sapply(1:827, \(i) sum(B[i, ] * w)),
        a ~ dnorm(100, 1),
        w ~ dnorm(0, 10),
        sigma ~ dexp(1)
    ),
    data = list(D = d2$doy, B = B),
    start = list(w = rep(0, ncol(B)))
)
```

### 4.5.3 Smooth functions for a rough world

## 4.6 Summary

## 4.7 Practice

### 4E1

### 4E2

### 4E4

### 4E5

### 4M1

### 4M2

### 4M3

### 4M4

### 4M5

### 4M6

### 4M7

### 4M8

### 4H1

### 4H2

### 4H3

### 4H4

### 4H5

### 4H6

### 4H7