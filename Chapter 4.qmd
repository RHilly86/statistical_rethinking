---
title: "Chapter 4"
format: html
---

```{julia}
using Distributions
using DataFrames
using DataFrames: transform
using Chain
using CairoMakie
using StatisticalRethinking
using StatisticalRethinking: link
using CSV
using Turing
using BSplines
```

## 4.1 Why normal distributions are normal

### 4.1.1 Normal by addition

```{julia}
pos = [sum(rand(Uniform(-1, 1), 16)) for _ in 1:1000]
pos = map(i -> sum(rand(Uniform(-1, 1), 16)), 1:1000)
```

```{julia}
f = Figure()
ax = Axis(f[1, 1])

density!(ax, pos)
f
```

```{julia}
f = Figure()
ax = Axis(f[1, 1])
x_range = 1:16

for _ in 1:1000
    movements = cumsum(rand(Uniform(-1, 1), 16))
    lines!(ax, x_range, movements, color = (:black, 0.25))
end

f
```

### 4.1.2 Normal by multiplication

```{julia}
prod(1 .+ rand(Uniform(0, 0.1), 12))
```

```{julia}
growth = [prod(1 .+ rand(Uniform(0, 0.1), 12)) for _ in 1:10_000]
f = Figure()
ax = Axis(f[1, 1])
density!(ax, growth)
f
```

```{julia}
big = [prod(1 .+ rand(Uniform(0, 0.5), 12)) for _ in 1:10_000]
small = [prod(1 .+ rand(Uniform(0, 0.1), 12)) for _ in 1:10_000]
```

### 4.1.3 Normal by log-multiplication
```{julia}
log_big = [log(prod(1 .+ rand(Uniform(0, 0.5), 12))) for _ in 1:10_000]
```

### 4.1.4 Using Gaussian distributions

## 4.2 A language for describing models

### 4.2.1 Re-describing the globe tossing model

```{julia}
w = 6
n = 9
p_grid = range(start=0, stop=1, length=100)
posterior = pdf.(Binomial.(n, p_grid), w) .* pdf.(Uniform(0, 1), p_grid)
posterior = posterior / sum(posterior)
```

## 4.3 Gaussian model of height

### 4.3.1 The data

```{julia}
howell1 = CSV.read("Howell1.csv", DataFrame; delim=";")
```

```{julia}
describe(howell1)
```

```{julia}
precis(howell1)
```

```{julia}
howell1[:, :height]
```

```{julia}
d2 = subset(howell1, :age => ByRow(age -> age .>= 18))
```

### 4.3.2 The model

```{julia}
avg_height = 100:250
prior = Normal(178, 20)
likelihood = pdf.(prior, avg_height)

f = Figure()
ax = Axis(f[1, 1])
lines!(ax, avg_height, likelihood)
f
```

```{julia}
avg_spread = -10:60
prior = Uniform(0, 50)
likelihood = pdf.(prior, avg_spread)

f = Figure()
ax = Axis(f[1, 1])
lines!(ax, avg_spread, likelihood)
f
```

```{julia}
sample_mu = rand(Normal(178, 20), 10_000)
sample_sigma = rand(Uniform(0, 50), 10_000)
prior_h = rand.(Normal.(sample_mu, sample_sigma))
```

```{julia}
f = Figure()
ax = Axis(f[1, 1])
density!(ax, prior_h)
f
```

```{julia}
sample_mu = rand(Normal(178, 100), 10_000)
prior_h = rand.(Normal.(sample_mu, sample_sigma))
```

```{julia}
f = Figure()
ax = Axis(f[1, 1])
density!(ax, prior_h)
f
```

### 4.3.3 Grid approximation of the posterior distribution
```{julia}
mu_list = range(start=150, stop=160, length=100)
sigma_list = range(start=7, stop=9, length=100)
post = DataFrame(Iterators.product(mu_list, sigma_list), [:mu, :sigma])
post[:, :log_likelihood] = map(
    (mu, sigma) -> sum(logpdf.(Normal(mu, sigma), d2[:, :height])),
    post[:, :mu], post[:, :sigma]
)
post[:, :product] = post[:, :log_likelihood] + 
                    logpdf.(Normal(178, 20), post[:, :mu]) +
                    logpdf.(Uniform(0, 50), post[:, :sigma])
# NOTE: This is the unnormalized posterior!
post[:, :prob] = exp.(post[:, :product] .- maximum(post[:, :product]))
```

```{julia}
f = Figure()
ax = Axis(f[1, 1])

contour!(ax, post[:, :mu], post[:, :sigma], post[:, :prob])
f
```

```{julia}
f = Figure()
ax = Axis(f[1, 1])

heatmap!(ax, post[:, :mu], post[:, :sigma], post[:, :prob])
f
```

### 4.3.4 Sampling from the posterior

```{julia}
sample_rows = sample(1:nrow(post), Weights(post[:, :prob]), 10_000, replace=true)
sample_mu = post[sample_rows, :mu]
sample_sigma = post[sample_rows, :sigma]
```

```{julia}
f = Figure()
ax = Axis(f[1, 1])

scatter!(ax, sample_mu, sample_sigma, color = (:blue, 0.15))
f
```

```{julia}
f = Figure()
ax = Axis(f[1, 1])

density!(ax, sample_mu)
f
```

```{julia}
f = Figure()
ax = Axis(f[1, 1])

density!(ax, sample_sigma)
f
```

```{julia}
PI(sample_mu)
PI(sample_sigma)
```

```{julia}
d3 = sample(d2[:, :height], 20)
```

```{julia}
mu_list = range(start=150, stop=170, length=200)
sigma_list = range(start=4, stop=20, length=200)
post2 = DataFrame(Iterators.product(mu_list, sigma_list), [:mu, :sigma])

post2[:, :log_likelihood] = map(
    (mu, sigma) -> sum(logpdf.(Normal(mu, sigma), d3)),
    post2[:, :mu], post2[:, :sigma]
)
post2[:, :prod] = post2[:, :log_likelihood] +
                  logpdf.(Normal(178, 20), post2[:, :mu]) +
                  logpdf.(Uniform(0, 50), post2[:, :sigma])
post2[:, :prob] = exp.(post2[:, :prod] .- maximum(post2[:, :prod]))

sample2_rows = sample(1:nrow(post2), Weights(post2[:, :prob]), 10_000, replace=true)
sample2_mu = post2[sample2_rows, :mu]
sample2_sigma = post2[sample2_rows, :sigma]
```

```{julia}
f = Figure()
ax = Axis(f[1, 1])

scatter!(ax, sample2_mu, sample2_sigma, color=(:blue, 0.15))
f
```

```{julia}
f = Figure()
ax = Axis(f[1, 1])

density!(ax, sample2_sigma)
f
```

### 4.3.5 Finding the posterior distribution with quap
```{julia}
@model function m4_1(height)
    mu ~ Normal(178, 20)
    sigma ~ Uniform(0, 50)

    height ~ Normal(mu, sigma)
end

m4_1_model_output = sample(m4_1(d2[:, :height]), NUTS(), 1000)
summarystats(m4_1_model_output)
```

```{julia}
@model function m4_2(height)
    mu ~ Normal(178, 0.1)
    sigma ~ Uniform(0, 50)

    height ~ Normal(mu, sigma)
end

m4_2_model_output = sample(m4_2(d2[:, :height]), NUTS(), 1000)
summarystats(m4_2_model_output)
```

### 4.3.6 Sampling from a quap
```{julia}
posterior = DataFrame(
    mu = reshape(m4_1_model_output[:mu].data, 1000),
    sigma = reshape(m4_1_model_output[:sigma].data, 1000)
)
posterior
```

```{julia}
precis(posterior)
```

## 4.4 Linear Prediction
```{julia}
f = Figure()
ax = Axis(f[1, 1])
scatter!(ax, d2[:, :weight], d2[:, :height])
f
```

### 4.4.1 The linear model strategy

#### 4.4.1.1 Probability of the data

#### 4.4.1.2 Linear model

#### 4.4.1.3 Priors
```{julia}
N = 100
a = rand(Normal(178, 20), 100)
b = rand(Normal(0, 10), 100)
xbar = mean(d2[:, :weight])
x = range(start=minimum(d2[:, :weight]), stop=maximum(d2[:, :weight]), length=N)

f = Figure()
ax = Axis(f[1, 1])

for i in 1:N
    mu = a[i] .+ b[i] * (x .- xbar)
    lines!(ax, x, mu, color=(:black, 0.15))
end
f
```

```{julia}
b = rand(LogNormal(0, 1), 10_000)

f = Figure()
ax = Axis(f[1, 1])
density!(b)
f
```

```{julia}
N = 100 
a = rand(LogNormal(178, 20), N)
b = rand(LogNormal(0, 1), N)
```

### 4.4.2 Finding the posterior distribution
```{julia}
xbar = mean(d2[:, :weight])

@model function m4_3(height, weight)
    a ~ Normal(178, 20)
    b ~ LogNormal(0, 1)
    sigma ~ Uniform(0, 50)

    for i in 1:length(weight)
        mu = a .+ b * (weight .- mean(weight))
        height[i] ~ Normal(mu[i], sigma)
    end
end

m4_3_model_output = sample(m4_3(d2[:, :height], d2[:, :weight]), NUTS(), 1000)
```

### 4.4.3 Interpreting the posterior distribution
```{julia}
summarystats(m4_3_model_output)
```

```{julia}
f = Figure()
ax = Axis(f[1, 1])

post = DataFrame(
    a=reshape(m4_3_model_output[:a].data, 1000),
    b=reshape(m4_3_model_output[:b].data, 1000),
    sigma=reshape(m4_3_model_output[:sigma], 1000)
)

a_map = mean(post[:, :a])
b_map = mean(post[:, :b])
post_mean = a_map .+ b_map * (x .- xbar)

scatter!(ax, d2[:, :weight], d2[:, :height])
lines!(ax, x, post_mean)
f
```

```{julia}
N = 10
dN = d2[1:N, :]

@model function mN(weight, height)
    a ~ Normal(178, 20)
    b ~ LogNormal(0, 1)
    sigma ~ Uniform(0, 50)

    for i in 1:length(weight)
        mu = a .+ b * (weight .- mean(weight))
        height[i] ~ Normal(mu[i], sigma)
    end
end

mN_model_output = sample(mN(dN[:, :weight], dN[:, :height]), NUTS(), 1000)
```

```{julia}
post = DataFrame(
    a = reshape(mN_model_output[:a].data, 1000),
    b = reshape(mN_model_output[:b].data, 1000),
    sigma = reshape(mN_model_output[:sigma].data, 1000)
)

post = sample(post, 20)
```

```{julia}
f = Figure()
ax = Axis(f[1, 1])

x = range(start=minimum(dN[:, :weight]), stop=maximum(dN[:, :weight]), length=N)

scatter!(ax, dN[:, :weight], dN[:, :height])
for i in 1:nrow(post)
    mu = post[i, :a] .+ post[i, :b] * (x .- mean(dN[:, :weight]))
    lines!(ax, x, mu, color = (:black, 0.15))
end

f
```

```{julia}
post = DataFrame(
    a = reshape(mN_model_output[:a].data, 1000),
    b = reshape(mN_model_output[:b].data, 1000),
    sigma = reshape(mN_model_output[:sigma].data, 1000)
)

mu_at_50 = post[:, :a] .+ post[:, :b] * (50 - xbar)
```

```{julia}
f = Figure()
ax = Axis(f[1, 1])
density!(mu_at_50)
f
```

```{julia}
PI(mu_at_50, perc_prob = 0.89)
mu = link(post, [:a :b], d2[:, :weight], xbar)
mu = hcat(mu...)
```

```{julia}
weight_seq = 25:70
mu = link(post, [:a :b], weight_seq, mean(weight_seq))
mu = hcat(mu...)
```

```{julia}
f = Figure()
ax = Axis(f[1, 1])

for i in 1:100
    scatter!(weight_seq, mu[i, :], color = (:blue, 0.2))
end
f
```

```{julia}
mu_mean = vcat(mean(mu, dims = 1)...)
mu_pi = PI.(eachcol(mu))
mu_pi = vcat(map(mu -> reshape(mu, (1, 2)), mu_pi)...)
```

```{julia}
f = Figure()
ax = Axis(f[1, 1])

scatter!(ax, d2[:, :weight], d2[:, :height])
lines!(ax, weight_seq, mu_mean)
band!(ax, weight_seq, mu_pi[:, 1], mu_pi[:, 2], color = (:orange, 0.2))
f
```

#### 4.4.3.5 Prediction intervals
```{julia}
m4_3_test = m4_3(Vector{Union{Missing, Float64}}(undef, length(weight_seq)), weight_seq)
# OR
m4_3_test = m4_3(repeat([missing], length(weight_seq)), weight_seq)

sim_height = predict(m4_3_test, m4_3_model_output)
```

```{julia}
sim_height_data = reshape(sim_height.value.data, (1000, 46))
mu_HPDI = transpose(mapslices(hpdi, mu, dims = 1))
height_PI = transpose(mapslices(PI, sim_height_data, dims = 1))

f = Figure()
ax = Axis(f[1, 1])

scatter!(ax, d2[:, :weight], d2[:, :height])
lines!(ax, weight_seq, mu_mean)
band!(ax, weight_seq, mu_HPDI[:, 1], mu_HPDI[:, 2], color = (:black, 0.2))
band!(ax, weight_seq, height_PI[:, 1], height_PI[:, 2], color = (:black, 0.2))
f
```

## 4.5 Curves from lines

### 4.5.1 Polynomial regression
```{julia}
d = howell1

d = @chain d begin
    transform(_, :weight => (weight -> (weight .- mean(weight)) /
                                       std(weight)) => :weight_s)
    transform(_, :weight_s => (weight_s -> weight_s .^ 2) => :weight_s2)
end

@model function m4_5(weight_s, weight_s2, height)
    a ~ Normal(178, 20)
    b1 ~ LogNormal(0, 1)
    b2 ~ Normal(0, 1)
    sigma ~ Uniform(0, 50)

    mu = a .+ b1 * weight_s .+ b2 * weight_s2
    for i in 1:length(weight_s)
        height[i] ~ Normal(mu[i], sigma)
    end
end

m4_5_model = m4_5(d[:, :weight_s], d[:, :weight_s2], d[:, :height])
m4_5_model_output = sample(m4_5_model, NUTS(), 1000)
```

```{julia}
summarystats(m4_5_model_output)
```

```{julia}
weight_seq = range(start = -2.2, stop = 2, length = 30)
pred_data = DataFrame(weight_seq = weight_seq, weight_s2 = weight_seq .^ 2)
mu = link(pred_data, [:weight_seq :weight_s2], weight_seq)
mu = hcat(mu...)
mu_mean = mean.(eachcol(mu))
mu_PI = transpose(mapslices(PI, mu, dims = 1))
```

```{julia}
m4_5_test_model = m4_5(pred_data[:, :weight_seq], pred_data[:, :weight_s2],
                  repeat([missing], length(pred_data[:, :weight_seq])))
sim_height = predict(m4_5_test_model, m4_5_model_output)
sim_height = reshape(sim_height.value.data, (1000, 30))
height_PI = transpose(mapslices(PI, sim_height, dims = 1))
```

```{julia}
f = Figure()
ax = Axis(f[1, 1])

scatter!(ax, d[:, :weight_s], d[:, :height])
lines!(ax, weight_seq, mu_mean)
band!(ax, weight_seq, mu_PI[:, 1], mu_PI[:, 2])
band!(ax, weight_seq, height_PI[:, 1], height_PI[:, 2])
f
```

```{julia}
d[:, :weight_s3] = d[:, :weight_s] .^ 3

@model function m4_6(weight_s, weight_s2, weight_s3, height)
    a ~ Normal(178, 20)
    b1 ~ LogNormal(0, 1)
    b2 ~ Normal(0, 10)
    b3 ~ Normal(0, 10)
    sigma ~ Uniform(0, 50)

    mu = a .+ b1 * weight_s .+ b2 * weight_s2 .+ b3 * weight_s3
    for (i, mu_i) in enumerate(mu)
        height[i] ~ Normal(mu_i, sigma)
    end
end

m4_6_model = m4_6(d.weight_s, d.weight_s2, d.weight_s3, d.height)
m4_6_model_output = sample(m4_6_model, NUTS(), 1000)
```

### 4.5.2 Splines
```{julia}
cherry_blossoms = CSV.read("cherry_blossoms.csv", DataFrame; delim = ";", missingstring = "NA")
d = cherry_blossoms
```

```{julia}
d2 = dropmissing(d, :doy)
d2 = disallowmissing(d2, [:year, :doy])
num_knots = 15
knots_list = quantile(d2[:, :year], range(0, 1, num_knots))
```

```{julia}
basis = BSplineBasis(3, knots_list)

f = Figure()
ax = Axis(f[1, 1])

xs = Matrix{Float64}(undef, 100, length(basis))
ys = similar(xs)
workspace = Vector{Float64}(undef, BSplines.order(basis))

```


```{julia}
for (idx, bspline) in enumerate(basis)
    xmin, xmax = BSplines.support(bspline)
    for (index, val) in enumerate(range(xmin, xmax, 100))
        println(bspline(val, workspace=Vector{Float64}(undef, BSplines.order(basis))))
    end
end
```